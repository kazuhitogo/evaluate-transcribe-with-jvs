{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "* transription_jobの結果を評価する\n",
    "* 2_kick_transcribeで起動したジョブが全て完了したころに実行すること\n",
    "\n",
    "# 成果物\n",
    "* 各ファイルごとの、正解の文字起こし結果と、transcribeの文字起こし結果と、WERのcsvファイル(ローカルに保存)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するライブラリのインストール\n",
    "# 形態素解析用に janome をインストール。mecab はインストールが面倒なので処理速度が遅いがインストールが容易な janome を利用\n",
    "!pip install janome\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from janome.tokenizer import Tokenizer\n",
    "import boto3,json,EvaluateSTT,Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数\n",
    "BUCKET_NAME = 'transcribe-output-bucket-202004161130'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('./label.csv')\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# S3 に出力された文字起こし結果を取得し、transcripts_resultに格納する\n",
    "transcripts_result = []\n",
    "for i,r in label_df.iterrows():\n",
    "    body = client.get_object(Bucket=BUCKET_NAME,Key=r[1]+\".json\")['Body'].read().decode('utf-8')\n",
    "    transcript = json.loads(body)['results']['transcripts'][0]['transcript'].replace(' ','')\n",
    "    transcripts_result.append(transcript)\n",
    "    if i % 100 == 99:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['transcripts_result'] = transcripts_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_csv('./eval.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('./eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = list(label_df['transcript_data'])\n",
    "pred_y = list(label_df['transcripts_result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WERの算出\n",
    "* 形態素解析したあとWERを算出する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_test_list = []\n",
    "segment_pred_list = []\n",
    "eval_list = []\n",
    "for test,pred in zip(test_y,pred_y):\n",
    "    segment_test = [token.surface for token in t.tokenize(test)]\n",
    "    segment_pred = [token.surface for token in t.tokenize(pred)]\n",
    "    segment_test_list.append(segment_test)\n",
    "    segment_pred_list.append(segment_pred)\n",
    "    evaluate = EvaluateSTT.Levenshtein_distance(segment_pred, segment_test)\n",
    "    result = EvaluateSTT.output_result(evaluate)\n",
    "    eval_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['transcript_data_segment'] = segment_test_list\n",
    "label_df['transcript_result_segment'] = segment_pred_list\n",
    "label_df['eval'] = eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['eval'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['WER'] = label_df['eval'].apply(lambda x: float(x[0][5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['levenshtein_distance'] = label_df.apply(lambda x: Levenshtein.distance(x[2],x[3]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['string_length'] = label_df['transcript_data'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 句読点を除去したWERの算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['transcript_data_remove_punctuation_marks'] = label_df['transcript_data'].apply(lambda x: x.replace('。','').replace('、',''))\n",
    "label_df['transcript_result_remove_punctuation_marks'] = label_df['transcripts_result'].apply(lambda x: x.replace('。','').replace('、',''))\n",
    "label_df['string_length_remove_punctuation_marks'] = label_df['transcript_data_remove_punctuation_marks'].apply(lambda x: len(x))\n",
    "label_df['levenshtein_distance_remove_punctuation_marks'] = label_df[['transcript_data_remove_punctuation_marks','transcript_result_remove_punctuation_marks']].apply(lambda x: Levenshtein.distance(x[0],x[1]),axis=1)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['accuracy_remove_punctuation_marks'] = 1-label_df['levenshtein_distance_remove_punctuation_marks']/label_df['string_length_remove_punctuation_marks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = list(label_df['transcript_data_remove_punctuation_marks'])\n",
    "pred_y = list(label_df['transcript_result_remove_punctuation_marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_test_list = []\n",
    "segment_pred_list = []\n",
    "eval_list = []\n",
    "for test,pred in zip(test_y,pred_y):\n",
    "    segment_test = [token.surface for token in t.tokenize(test)]\n",
    "    segment_pred = [token.surface for token in t.tokenize(pred)]\n",
    "    segment_test_list.append(segment_test)\n",
    "    segment_pred_list.append(segment_pred)\n",
    "    evaluate = EvaluateSTT.Levenshtein_distance(segment_pred, segment_test)\n",
    "    result = EvaluateSTT.output_result(evaluate)\n",
    "    eval_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['transcript_data_segment_remove_punctuation_marks'] = segment_test_list\n",
    "label_df['transcript_result_segment_remove_punctuation_marks'] = segment_pred_list\n",
    "label_df['eval_remove_punctuation_marks'] = eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['WER_remove_punctuation_marks'] = label_df['eval_remove_punctuation_marks'].apply(lambda x: float(x[0][5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['voice_type'] = label_df['file_path'].map(lambda x:x.split('/')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_csv('./eval.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.groupby('voice_type').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
